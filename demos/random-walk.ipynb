{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a4445-e8c7-4691-a49f-b28d578be0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0470ef1-4031-492c-b06f-f94af9b158d2",
   "metadata": {},
   "source": [
    "## Random walk and diffusion\n",
    "\n",
    "**Why are we doing this:** The example in this notebook -- random walk between a finite set of states or points -- becomes the diffusion equation in the limit as the number of states grows very large.\n",
    "It'll enable us to work out all the hard parts of discretizing diffusive-type problems in time first, without having to worry about space discretization.\n",
    "That'll come later.\n",
    "\n",
    "Our first example is diffusive transport.\n",
    "Diffusion shows up in all manner of settings ranging from from ecology to hillslope evolution.\n",
    "What we see at the macro-scale as diffusion often emerges from what is, at the micro-scale, a *random walk*.\n",
    "To pick a concrete example, we'll start by thinking about a rare isotope embedded in a crystal lattice.\n",
    "For example, you could think of a water molecule containing an ${}^{18}$O atom frozen into an ice core.\n",
    "We imagine that this molecule could reside at one of $N$ sites in the crystal lattice.\n",
    "This molecule will periodically jump from its current position to one of the neighboring sites on the lattice.\n",
    "To characterize what happens, we need to know (1) where does the molecule start? (2) what is the exepcted *holding time* $\\tau$ before the molecule will jump to another site? and (3) what are the neighboring sites and what is the probability of jumping to each site?\n",
    "\n",
    "We imagine a one-dimensional crystal lattice to start off, so the neighbors of site $k$ are $k + 1$ and $k - 1$.\n",
    "We suppose for now that the probabilities of going up or down are equal.\n",
    "Finally, we suppose that we know what the holding time $\\tau$ is.\n",
    "To simulate a sample trajectory of the particle, we proceed by:\n",
    "1. Generate an *exponential* random variable with intensity $\\tau$.\n",
    "2. Pick up or down with probability 1/2.\n",
    "\n",
    "The simplest setting of this problem assumes equal probability to go up as well as down.\n",
    "We can also look at situations where the isotope is more likely to go one direction than the other.\n",
    "This asymmetry is known as random walk with *drift*.\n",
    "We could also see what happens if the holding times vary within the lattice.\n",
    "I've used a 1D lattice so far because it's convenient.\n",
    "You could also imagine all of this taking place in higher dimensions.\n",
    "The algorithm for generating sample paths in these more complicated cases is essentially the same as what I described above.\n",
    "What we need are:\n",
    "$$\\begin{align}\n",
    "    \\tau_k & = \\text{ holding time in state } k \\\\\n",
    "    \\rho_{k\\to\\ell} & = \\text{ probability of transitioning from $k$ to $\\ell$}.\n",
    "\\end{align}$$\n",
    "We'll require that\n",
    "$$\\sum_\\ell \\rho_{k\\to\\ell} = 1$$\n",
    "for every state $k$, i.e. the sum of the transition probabilities to all other states is 1.\n",
    "\n",
    "#### Generating a sample path\n",
    "\n",
    "Now let's write some code so we can explore these ideas.\n",
    "The function below will generate a single sample path of a random walk.\n",
    "I've left some parts blank with comments.\n",
    "Fill them in and run the sample code below to see if it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761694ac-54ea-4c63-b9b0-f57b142f9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_path(\n",
    "    starting_state: int,\n",
    "    holding_times: np.ndarray,\n",
    "    probabilities: np.ndarray,\n",
    "    final_time: float,\n",
    "    rng: np.random.Generator,\n",
    "):\n",
    "    r\"\"\"Generate a single sample path of the continuous-time Markov chain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    starting_state:\n",
    "        The initial state or position of the Markov chain\n",
    "    holding_times:\n",
    "        How long the Markov chain spends on average in each state\n",
    "    probabilities:\n",
    "        A matrix such that `probabilities[i, j]` describes the probability of\n",
    "        transition from state `i` to state `j`\n",
    "    final_time:\n",
    "        How long to simulate for\n",
    "    rng:\n",
    "        A random number generator object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    states, times: np.ndarray, np.ndarray\n",
    "        Arrays describing the times of transitions and what state the system is\n",
    "        in after each transition\n",
    "    \"\"\"\n",
    "    i = starting_state\n",
    "    states, times = [i], [0.0]\n",
    "    while times[-1] < final_time:\n",
    "        dt = rng.exponential(holding_times[i])\n",
    "        neighbors, = probabilities[i, :].nonzero()\n",
    "        i = rng.choice(neighbors, p=probabilities[i, neighbors])\n",
    "        times.append(times[-1] + dt)\n",
    "        states.append(i)\n",
    "\n",
    "    return np.array(states), np.array(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16539a-4dcb-4111-8378-f6a7f637a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=1729)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fb10c-ae26-4714-829b-28625d688e9e",
   "metadata": {},
   "source": [
    "We'll start with a system consisting of 20 different possible states.\n",
    "Create two arrays, `holding_times` and `probabilities`.\n",
    "The holding times array will have shape `num_states` and will all be uniformly equal to 1.\n",
    "The `probabilities` array should have shape `(num_states, num_states)`.\n",
    "Make the probability of jumping from state `k` to `k + 1` equal to 0.45, and the probability of jumping from state `k` to `k - 1` equal to 0.55.\n",
    "We then have to do something special at the endpoints.\n",
    "Make the probability equal to 1 for jumping from state 0 to state 1, and for jumping from the last state to the second-to-last state.\n",
    "Make the holding time at the bottom (index \\#0) 2.0 instead of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964234d7-7cee-4c3d-84b7-1ee181747c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 20\n",
    "holding_times = ...\n",
    "probabilities = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7909b72-e7dd-4145-84fe-76e8540af7e7",
   "metadata": {},
   "source": [
    "The helper function below plots a single sample path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8e462-6821-4c11-9e57-61d7a1fd6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_path(xs, ts, ax, color=\"tab:blue\", **kwargs):\n",
    "    for t1, t2, x1, x2 in zip(ts[:-1], ts[1:], xs[:-1], xs[1:]):\n",
    "        ax.plot([t1, t2], [x1, x1], color=color, **kwargs)\n",
    "        ax.plot([t2, t2], [x1, x2], color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fef335-f963-407b-8448-c4148fbb4949",
   "metadata": {},
   "source": [
    "And this will plot a few sample paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f776202-2c1f-4557-ba91-05edd9812ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=1729)\n",
    "\n",
    "starting_state = num_states // 2\n",
    "final_time = 100.0\n",
    "args = (starting_state, holding_times, probabilities, final_time, rng)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for color in [\"tab:blue\", \"tab:green\", \"tab:orange\"]:\n",
    "    xs, ts = generate_sample_path(*args)\n",
    "    show_sample_path(xs, ts, ax, color=color, alpha=0.5)\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"state\")\n",
    "ax.set_xlim((0, final_time))\n",
    "ax.set_ylim((0, num_states));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d6f12-9919-4a90-a6ce-92548dbe7c1a",
   "metadata": {},
   "source": [
    "**Exercise:** Can you think of other physical systems that are random walks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16f550-c85e-4fa6-bb04-31b23e89afd9",
   "metadata": {},
   "source": [
    "#### Many sample paths\n",
    "\n",
    "Now suppose we were to look at a very large number of realizations or sample paths of this process.\n",
    "We can summarize its behavior by looking at the time-evolving probability mass\n",
    "$$p_k(t) = \\text{fraction of sample paths that are at state $k$ at time $t$}.$$\n",
    "We can pack all of these into a vector $p(t) = \\{p_1(t), \\ldots, p_N(t)\\}$.\n",
    "**Can we describe how $p$ evolves in time?**\n",
    "\n",
    "Before we try to answer that question, let's generate a whole lot more sample paths and see what the density looks like at a bunch of snapshots in time.\n",
    "The code below is a helper function that will take a partially computed probability density $p$ at several times and a single sample path, and add that path's contribution into the density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24715bf7-1216-4720-b607-4d785fe5cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_density(\n",
    "    density: np.ndarray,\n",
    "    times: np.ndarray,\n",
    "    states: np.ndarray,\n",
    "    final_time: float,\n",
    "):\n",
    "    num_times = density.shape[1]\n",
    "    dt = final_time / num_times\n",
    "    for t1, t2, state in zip(times[:-1], times[1:], states[:-1]):\n",
    "        for index in range(int(t1 / dt), min(int(t2 / dt), num_times)):\n",
    "            density[state, index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5118c0e-caea-4fe9-809e-350969b9e594",
   "metadata": {},
   "source": [
    "Next, we'll generate 1000 sample paths, all of them starting from the same point, and fill up the empirical density.\n",
    "Here I'm using a package called tqdm so that we can see a progress bar.\n",
    "If you're doing long-running computations, this can be really helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0d34a-93b8-4d45-ad4e-cd03d664d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times = 100\n",
    "density = np.zeros((num_states, num_times))\n",
    "\n",
    "num_trials = 1000\n",
    "for trial in tqdm.trange(num_trials):\n",
    "    xs, ts = generate_sample_path(*args)\n",
    "    sum_density(density, ts, xs, final_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad46763-0ac8-4500-8359-d5de0eee48e9",
   "metadata": {},
   "source": [
    "Let's look at the results.\n",
    "Observe how the states tend to cluster near the bottom.\n",
    "Makes sense right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de39d0f-0b03-4641-9bff-98c95aa632e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(density / num_trials, origin=\"lower\")\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"state\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58cdc2-cede-404a-aca4-2ad90585e90c",
   "metadata": {},
   "source": [
    "Now we'll zoom in on the last half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974e85c-1756-44be-9234-72b2a9417a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(density[:, num_times // 2:] / num_trials, origin=\"lower\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f33968-d927-41f0-940e-7dd7483315ca",
   "metadata": {},
   "source": [
    "#### Density evolution\n",
    "\n",
    "Ok that was neat I suppose.\n",
    "Can we describe how the probability density would evolve if we were able to take infinitely many trials?\n",
    "\n",
    "We can observe that the rate of change of probability in $p_k$ is the difference of two terms.\n",
    "Probability can flow into $k$ from other states $\\ell$, and probability can flow out of $k$ into other states $\\ell$.\n",
    "The rates are determined by the holding times and transition probabilities:\n",
    "$$\\dot p_k = \\underbrace{\\sum_\\ell\\frac{\\rho_{\\ell\\to k}}{\\tau_\\ell}p_\\ell}_{\\text{flux in}} - \\underbrace{\\sum_\\ell\\frac{\\rho_{k\\to\\ell}}{\\tau_k}p_k}_{\\text{flux out}}$$\n",
    "We can turn all of this into linear algebra.\n",
    "We define the *generator* matrix $A$ as\n",
    "$$A = \\left(I - \\rho^*\\right)\\text{diag}(\\tau)^{-1}$$\n",
    "and this describes how the probability evolves as\n",
    "\\begin{equation}\n",
    "    \\dot p = -A\\, p.\n",
    "\\end{equation}\n",
    "Remember that all the transition probabilities (the rows of $\\rho$) have to add up to 1.\n",
    "What this means is -- and you might want to try some examples -- that if we take the transpose of $A$ and multiply it by all 1s, we get 0:\n",
    "\\begin{equation}\n",
    "    A^*\\mathbf 1 = 0.\n",
    "\\end{equation}\n",
    "This means that\n",
    "\\begin{equation}\n",
    "    \\det A^* = \\det A = 0,\n",
    "\\end{equation}\n",
    "so there must be some other non-zero vector $p_{\\text{eq}}$ such that $A\\cdot p_{\\text{eq}} = 0$.\n",
    "This special vector $p_{\\text{eq}}$ is the *equilibrium* density.\n",
    "In the computational exercises, you'll try a bunch of cases and see how things evolve.\n",
    "\n",
    "Fill in the body of the function below to compute the rate matrix from the holding times and transition probabilities.\n",
    "Remember how to compute transposes of arrays, how to form the identity matrix, and how to [form a diagonal matrix](https://numpy.org/doc/stable/reference/generated/numpy.diag.html) from a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8079c-5674-4e2a-8ba5-dd7022357764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rate_matrix(holding_times, probabilities):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9227e-98bd-4d95-a641-0ac1a86a0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = make_rate_matrix(holding_times, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f20539-fbca-4238-a0fe-4889281e4bc2",
   "metadata": {},
   "source": [
    "Compute the eigendecomposition of the rate matrix $A$ and save the results in two variables `λ`, `V`.\n",
    "Print out the eigenvalues.\n",
    "If you formed the rate matrix correctly, the eigenvalues should all be real or have negligible imaginary parts, there should be one eigenvalue very close to zero (that's the equilibrium density), and the remaining eigenvalues should all be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90861233-716f-44e2-aab8-a8d4fe744b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2abf2c60-e7c2-4067-85ea-5efab7a2c82c",
   "metadata": {},
   "source": [
    "The eigendecomposition routines in numpy and scipy don't give any guarantees about what order the eigenvalues and eigenvectors are in.\n",
    "The function [np.argsort](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) will return a list of integer indices describing how to permute an array so that it's in order.\n",
    "Redefine the arrays of eigenvalues and eigenvectors using this permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f63443-dbf8-411e-b64a-1de556d5f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = np.argsort(np.abs(λs))\n",
    "λ = λ[permutation]\n",
    "V = V[:, permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd63b3-6abe-4f43-83f7-135a489bd0ef",
   "metadata": {},
   "source": [
    "The scatter plot below will show all the eigenvalues; if you permuted them correctly, you should see them getting larger to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6cd96-9b15-42bb-979b-673660c52fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(np.linspace(0, num_states, num_states), λ.real);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aea712-9a53-430c-bf73-e92af30b2f8a",
   "metadata": {},
   "source": [
    "The eigendecomposition algorithm also doesn't give any guarantees about the normalization of the eigenvectors.\n",
    "For example, you and I know that the eigenvector corresponding to the eigenvalue $\\lambda = 0$ represents the equilibrium probability density $p_{eq}$, so all of its entries should be positive and the total probability should be equal to 1 ($\\mathbf{1}^*p_{eq} = 1$).\n",
    "But we can multiply an eigenvector of a matrix by any non-zero number and it's still an eigenvector.\n",
    "Define a variable `p_eq` to be the 0th eigenvector of $A$, normalize the result to 1, and plot it.\n",
    "What do you observe about it and does it make sense given the rules that we created for how the system evolves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e04f2-b955-4b5a-8726-8f5022d83aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_eq = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7834f2b-5636-4b28-8383-eca276129772",
   "metadata": {},
   "source": [
    "The eigenvalues of $A$ have units of inverse time, so their reciprocals are natural timescales for the problem.\n",
    "The 0th eigenvalue of $A$ is close to 0, so its reciprocal is basically infinity.\n",
    "If we take the reciprocal of the next eigenvalue (index \\#1) and the last eigenvalue, these will give us respectively the time for the longest and shortest modes to decay.\n",
    "Compute these timescales, save them in variables `longest_timescale` and `shortest_timescale`, and print out their values.\n",
    "Remember that you can get the last element of an array `q` with `q[-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d9d94-9285-41db-9d89-643c28c41e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dc952dd-3cce-482a-bb45-9e3548a3d8d1",
   "metadata": {},
   "source": [
    "Now we'll compute the evolution of the probability density, which we'll store in a variable called `ps`.\n",
    "One index will represent states and another index will be time.\n",
    "But we have a choice -- should the shape be `(num_steps + 1, num_states)` or should it be `(num_states, num_steps + 1)`?\n",
    "The answer is: yes.\n",
    "We'll go with the first choice `(num_steps + 1, num_states)`.\n",
    "If we want to peel off the probability density at time index `n`, we can do this with `ps[n, :]`, but numpy also gives us the shorthand `ps[n]` which is particularly convenient.\n",
    "There are also performance reasons for doing this.\n",
    "\n",
    "Create an zero array `ps` of shape `(num_steps + 1, num_states)`.\n",
    "Then set `ps[0, starting_state]` to be equal to 1, representing our initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46a86f-3800-42ff-892d-e0d6fbc3fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 256\n",
    "ps = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befedafb-c7e2-41ec-b08d-6830f409c371",
   "metadata": {},
   "source": [
    "We'll make our simulation run for twice the longest timescale that you computed above.\n",
    "Save the duration `dt` of one timestep; this should be the final time divided by the number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5f4a2-2d0c-449f-a86f-b691334814cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033d06e-2819-41d5-9f3c-cd919ddeac01",
   "metadata": {},
   "source": [
    "In the previous notebook, we computed the application of the matrix exponential using a formula expressed in terms of the eigenvalues and eigenvectors of $A$.\n",
    "The scipy package, which builds on many of the routines in numpy, has a routine to compute the matrix exponential directly.\n",
    "If we want to compute\n",
    "$$p(n\\cdot dt) = \\exp(-n\\cdot dt\\cdot A)p_0,$$\n",
    "we can also do\n",
    "$$p(n\\cdot dt) = \\underbrace{\\exp(-dt\\cdot A)\\cdot\\ldots\\cdot \\exp(-dt\\cdot A)}_{n\\text{ times}}p_0.$$\n",
    "(Why can we do this?)\n",
    "But if we already computed $p((n - 1)dt)$, then we don't have to compute a bunch of matrix powers -- we can just do\n",
    "$$ps(n\\cdot dt) = \\exp(-dt\\cdot A)p((n - 1)dt).$$\n",
    "The upshot of all this is that we can compute the matrix\n",
    "$$G = \\exp(-dt\\cdot A)$$\n",
    "once and use it over and over again.\n",
    "Compute this matrix below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c80c53-1c0f-430f-a30b-a5e7539de574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12247bf7-1d47-43ef-aac4-83865ea89925",
   "metadata": {},
   "source": [
    "Now write a loop to fill in the array `ps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d5d8f-3ad6-4d91-8cea-21d7ed6f2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(num_steps):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a92455-ce01-4c02-bd5f-7c81d970684e",
   "metadata": {},
   "source": [
    "If you did everything right, this should make a movie of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9edbb1-d23d-4863-a101-039ba4fc55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots()\n",
    "line, = ax.plot(ps[0])\n",
    "def animate(p):\n",
    "    line.set_ydata(p)\n",
    "animation = FuncAnimation(fig, animate, ps, interval=1e3/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2b71e-c34c-46b0-9c60-8f6649b2820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animation.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36486bf-58d0-4f69-92d8-76f36793e63a",
   "metadata": {},
   "source": [
    "To wrap things up, let's look at the projection of the probability density at each time onto 0th, 1th, and last eigenvectors of $A$.\n",
    "I've normalized them so that the magnitudes of both are the same at the start.\n",
    "Notice how the one mode decays much faster than the other.\n",
    "What do you think happens to this contrast in timescales when we take more and more states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba09d2-1510-4d9e-be67-06b01c506061",
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = np.linalg.solve(V, ps.T).T\n",
    "ts = np.linspace(0, 2 * longest_timescale, num_steps + 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.plot(ts, abs(projections[:, 1] / projections[0, 1]), label=\"longest\")\n",
    "ax.plot(ts, abs(projections[:, -1] / projections[0, -1]), label=\"shortest\")\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
